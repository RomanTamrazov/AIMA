import json
import requests
from bs4 import BeautifulSoup
from datetime import datetime, timedelta
import time
import random
import asyncio
import os
import aiohttp
from urllib.parse import quote

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º config –∏–∑ –∫–æ—Ä–Ω—è
import sys
sys.path.append(os.path.dirname(os.path.dirname(__file__)))
import config

from src.parsers.sources import EventSources
from src.ai.search_manager import SearchManager

class WebSearcher:
    """–ö–ª–∞—Å—Å –¥–ª—è —Ä–µ–∞–ª—å–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏–π –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ"""
    
    def __init__(self):
        self.session = None
    
    async def search_real_events(self, query, max_events=10):
        """–†–µ–∞–ª—å–Ω—ã–π –ø–æ–∏—Å–∫ –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏–π –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ"""
        print(f"üåê –ò—â–µ–º —Ä–µ–∞–ª—å–Ω—ã–µ –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏—è: '{query}'")
        
        if not self.session:
            self.session = aiohttp.ClientSession()
        
        try:
            events = []
            
            # 1. –ü–æ–∏—Å–∫ —á–µ—Ä–µ–∑ Google (—É–ø—Ä–æ—â–µ–Ω–Ω—ã–π)
            google_events = await self._search_google(query)
            events.extend(google_events)
            
            # 2. –ü–æ–∏—Å–∫ –Ω–∞ —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø–ª–∞—Ç—Ñ–æ—Ä–º–∞—Ö
            platform_events = await self._search_platforms(query)
            events.extend(platform_events)
            
            # 3. –ü–æ–∏—Å–∫ –Ω–∞ —Å–∞–π—Ç–∞—Ö —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç–æ–≤
            university_events = await self._search_universities(query)
            events.extend(university_events)
            
            # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
            unique_events = self._remove_duplicates(events)
            
            print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(unique_events)} —Ä–µ–∞–ª—å–Ω—ã—Ö –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏–π")
            return unique_events[:max_events]
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –≤–µ–±-–ø–æ–∏—Å–∫–∞: {e}")
            return []
    
    async def _search_google(self, query):
        """–ü–æ–∏—Å–∫ —á–µ—Ä–µ–∑ Google"""
        try:
            search_url = f"https://www.google.com/search?q={quote(query)}+–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥+–º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏–µ+2024+2025"
            
            headers = {
                "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
            }
            
            async with self.session.get(search_url, headers=headers, timeout=10) as response:
                if response.status == 200:
                    html = await response.text()
                    return self._parse_google_results(html, query)
                else:
                    return []
                    
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ Google –ø–æ–∏—Å–∫–∞: {e}")
            return []
    
    def _parse_google_results(self, html, query):
        """–ü–∞—Ä—Å–∏—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã Google"""
        events = []
        soup = BeautifulSoup(html, 'html.parser')
        
        # –ò—â–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–∏ —Å –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏—è–º–∏
        for link in soup.find_all('a', href=True):
            title = link.get_text().strip()
            url = link['href']
            
            # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —Å—Å—ã–ª–∫–∏
            if (any(keyword in title.lower() for keyword in ['–º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏–µ', 'event', '–∫–æ–Ω—Ñ–µ—Ä–µ–Ω—Ü–∏—è', 'conference', '–º–∏—Ç–∞–ø', 'meetup', '—Ö–∞–∫–∞—Ç–æ–Ω', 'hackathon']) and
                'google' not in url):
                
                event = {
                    "title": title[:100],
                    "url": url if url.startswith('http') else f"https://www.google.com{url}",
                    "source": "google_search",
                    "description": f"–ù–∞–π–¥–µ–Ω–æ –ø–æ –∑–∞–ø—Ä–æ—Å—É: {query}",
                    "date": self._estimate_date(),
                    "location": "–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥",
                    "type": self._detect_event_type(title),
                    "audience": random.randint(50, 300),
                    "themes": [query],
                    "speakers": ["–°–ø–∏–∫–µ—Ä—ã –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏—è"],
                    "registration_info": "–£—Ç–æ—á–Ω—è–µ—Ç—Å—è"
                }
                events.append(event)
        
        return events[:5]  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ
    
    async def _search_platforms(self, query):
        """–ü–æ–∏—Å–∫ –Ω–∞ –ø–ª–∞—Ç—Ñ–æ—Ä–º–∞—Ö –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏–π"""
        events = []
        
        platforms = [
            {
                "name": "TimePad",
                "url": f"https://timepad.ru/search/events/?q={quote(query)}&categories=technology"
            },
            {
                "name": "Meetup.com", 
                "url": f"https://www.meetup.com/find/?keywords={quote(query)}&location=ru--St-Petersburg"
            }
        ]
        
        for platform in platforms:
            try:
                headers = {
                    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
                }
                
                async with self.session.get(platform['url'], headers=headers, timeout=10) as response:
                    if response.status == 200:
                        html = await response.text()
                        platform_events = self._parse_platform_results(html, platform['name'], query)
                        events.extend(platform_events)
                        
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –Ω–∞ {platform['name']}: {e}")
                continue
        
        return events
    
    def _parse_platform_results(self, html, platform_name, query):
        """–ü–∞—Ä—Å–∏—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å –ø–ª–∞—Ç—Ñ–æ—Ä–º"""
        events = []
        soup = BeautifulSoup(html, 'html.parser')
        
        # –≠–≤—Ä–∏—Å—Ç–∏–∫–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞ —Å–æ–±—ã—Ç–∏–π (—É–ø—Ä–æ—â–µ–Ω–Ω–∞—è)
        event_elements = soup.find_all(['h3', 'h4', 'h5', 'a'], string=True)
        
        for element in event_elements:
            text = element.get_text().strip()
            if (any(keyword in text.lower() for keyword in ['event', 'meetup', '–∫–æ–Ω—Ñ–µ—Ä–µ–Ω—Ü–∏—è', '–º–∏—Ç–∞–ø', '—Ö–∞–∫–∞—Ç–æ–Ω']) and
                len(text) > 10):
                
                event = {
                    "title": text[:100],
                    "source": f"{platform_name}_search",
                    "description": f"–ù–∞–π–¥–µ–Ω–æ –Ω–∞ {platform_name} –ø–æ –∑–∞–ø—Ä–æ—Å—É: {query}",
                    "date": self._estimate_date(),
                    "location": "–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥", 
                    "type": self._detect_event_type(text),
                    "audience": random.randint(30, 200),
                    "themes": [query],
                    "speakers": ["–û—Ä–≥–∞–Ω–∏–∑–∞—Ç–æ—Ä—ã –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏—è"],
                    "registration_info": f"–†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –Ω–∞ {platform_name}",
                    "url": "#"
                }
                events.append(event)
        
        return events[:3]
    
    async def _search_universities(self, query):
        """–ü–æ–∏—Å–∫ –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏–π –≤ —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç–∞—Ö"""
        events = []
        
        universities = [
            {"name": "–ò–¢–ú–û", "url": "https://events.itmo.ru/"},
            {"name": "–°–ü–±–ì–£", "url": "https://events.spbu.ru/"},
            {"name": "–ü–æ–ª–∏—Ç–µ—Ö", "url": "https://www.spbstu.ru/events/"}
        ]
        
        for uni in universities:
            try:
                headers = {
                    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
                }
                
                async with self.session.get(uni['url'], headers=headers, timeout=10) as response:
                    if response.status == 200:
                        html = await response.text()
                        uni_events = self._parse_university_events(html, uni['name'])
                        events.extend(uni_events)
                        
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –≤ {uni['name']}: {e}")
                continue
        
        return events
    
    def _parse_university_events(self, html, university_name):
        """–ü–∞—Ä—Å–∏—Ç –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏—è —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç–æ–≤"""
        events = []
        soup = BeautifulSoup(html, 'html.parser')
        
        # –≠–≤—Ä–∏—Å—Ç–∏–∫–∞ –¥–ª—è —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç—Å–∫–∏—Ö –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏–π
        event_indicators = ['–º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏–µ', '—Å–æ–±—ã—Ç–∏–µ', 'event', '–∫–æ–Ω—Ñ–µ—Ä–µ–Ω—Ü–∏—è', '—Å–µ–º–∏–Ω–∞—Ä']
        
        for element in soup.find_all(string=True):
            text = element.strip()
            if any(indicator in text.lower() for indicator in event_indicators) and len(text) > 20:
                
                event = {
                    "title": f"{text[:80]} - {university_name}",
                    "source": f"{university_name}_parsed",
                    "description": f"–ú–µ—Ä–æ–ø—Ä–∏—è—Ç–∏–µ –≤ {university_name}",
                    "date": self._estimate_date(),
                    "location": f"–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥, {university_name}",
                    "type": "–æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–æ–µ –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏–µ", 
                    "audience": random.randint(50, 150),
                    "themes": ["–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ", "–Ω–∞—É–∫–∞", "IT"],
                    "speakers": [f"–ü—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª–∏ {university_name}"],
                    "registration_info": "–†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –Ω–∞ —Å–∞–π—Ç–µ —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç–∞",
                    "url": "#"
                }
                events.append(event)
        
        return events[:2]
    
    def _estimate_date(self):
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—É—é –¥–∞—Ç—É"""
        days = random.randint(7, 180)  # –æ—Ç 1 –Ω–µ–¥–µ–ª–∏ –¥–æ 6 –º–µ—Å—è—Ü–µ–≤
        return (datetime.now() + timedelta(days=days)).strftime("%Y-%m-%d")
    
    def _detect_event_type(self, title):
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ç–∏–ø –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏—è –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é"""
        title_lower = title.lower()
        
        if any(word in title_lower for word in ['–∫–æ–Ω—Ñ–µ—Ä–µ–Ω—Ü–∏—è', 'conference']):
            return '–∫–æ–Ω—Ñ–µ—Ä–µ–Ω—Ü–∏—è'
        elif any(word in title_lower for word in ['–º–∏—Ç–∞–ø', 'meetup']):
            return '–º–∏—Ç–∞–ø' 
        elif any(word in title_lower for word in ['—Ö–∞–∫–∞—Ç–æ–Ω', 'hackathon']):
            return '—Ö–∞–∫–∞—Ç–æ–Ω'
        elif any(word in title_lower for word in ['—Å–µ–º–∏–Ω–∞—Ä', 'workshop']):
            return '—Å–µ–º–∏–Ω–∞—Ä'
        elif any(word in title_lower for word in ['–ª–µ–∫—Ü–∏—è', 'lecture']):
            return '–ª–µ–∫—Ü–∏—è'
        else:
            return '–º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏–µ'
    
    def _remove_duplicates(self, events):
        """–£–¥–∞–ª—è–µ—Ç –¥—É–±–ª–∏–∫–∞—Ç—ã"""
        seen_titles = set()
        unique_events = []
        
        for event in events:
            title = event['title'].lower().strip()
            if title not in seen_titles:
                seen_titles.add(title)
                unique_events.append(event)
        
        return unique_events
    
    async def close(self):
        """–ó–∞–∫—Ä—ã–≤–∞–µ—Ç —Å–µ—Å—Å–∏—é"""
        if self.session:
            await self.session.close()

class EventParser:
    """–£–ª—É—á—à–µ–Ω–Ω—ã–π –ø–∞—Ä—Å–µ—Ä –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏–π —Å LLM-–ø–æ–∏—Å–∫–æ–º –∏ —Ä–µ–∞–ª—å–Ω—ã–º –≤–µ–±-–ø–æ–∏—Å–∫–æ–º"""
    
    def __init__(self):
        self.sources = EventSources()
        self.search_manager = SearchManager()
        self.web_searcher = WebSearcher()  # ‚¨ÖÔ∏è –î–û–ë–ê–í–õ–ï–ù–û —Ä–µ–∞–ª—å–Ω—ã–π –ø–æ–∏—Å–∫
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        })
    
    async def parse_events(self, use_llm_search=True, use_real_parsing=False, use_web_search=True):
        """
        –û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –ø–∞—Ä—Å–∏–Ω–≥–∞ –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏–π —Å LLM-–ø–æ–∏—Å–∫–æ–º –∏ –≤–µ–±-–ø–æ–∏—Å–∫–æ–º
        """
        print("üîÑ –ù–∞—á–∏–Ω–∞–µ–º –ø–∞—Ä—Å–∏–Ω–≥ –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏–π...")
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏—è –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
        events = self.load_events()
        
        # –†–ï–ê–õ–¨–ù–´–ô –í–ï–ë-–ü–û–ò–°–ö (–Ω–æ–≤–æ–µ!)
        if use_web_search:
            print("üåê –ó–∞–ø—É—Å–∫–∞–µ–º —Ä–µ–∞–ª—å–Ω—ã–π –ø–æ–∏—Å–∫ –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ...")
            web_events = await self._search_real_web_events()
            events.extend(web_events)
            print(f"‚úÖ –í–µ–±-–ø–æ–∏—Å–∫ –Ω–∞—à–µ–ª {len(web_events)} –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏–π")
        
        # LLM-–ø–æ–∏—Å–∫
        if use_llm_search and (len(events) < 10 or use_real_parsing):
            print("üß† –ò—Å–ø–æ–ª—å–∑—É–µ–º LLM –¥–ª—è —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è –±–∞–∑—ã –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏–π...")
            llm_events = await self._search_with_llm()
            events.extend(llm_events)
        
        # –†–µ–∞–ª—å–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ —Å —Å–∞–π—Ç–æ–≤
        if use_real_parsing:
            real_events = self.sources.parse_real_events()
            events.extend(real_events)
        else:
            sample_events = self.sources.get_sample_events()
            events.extend(sample_events)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –ø–∞—Ä—Å–∏–Ω–≥ —Å —Ä–µ–∞–ª—å–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
        try:
            additional_events = self._parse_additional_sources()
            if additional_events:
                events.extend(additional_events)
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ –ø–∞—Ä—Å–∏–Ω–≥–∞: {e}")
        
        # –û—á–∏—Å—Ç–∫–∞ –æ—Ç –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
        events = self._remove_duplicates(events)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö
        self.save_events(events)
        
        print(f"‚úÖ –ü–∞—Ä—Å–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω. –ù–∞–π–¥–µ–Ω–æ {len(events)} –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏–π")
        return events
    
    async def _search_real_web_events(self):
        """–†–µ–∞–ª—å–Ω—ã–π –ø–æ–∏—Å–∫ –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏–π –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ"""
        search_queries = [
            "IT –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏—è –°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥ 2024",
            "—Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∫–æ–Ω—Ñ–µ—Ä–µ–Ω—Ü–∏–∏ –°–ü–±",
            "–º–∏—Ç–∞–ø—ã –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ –°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥", 
            "—Ö–∞–∫–∞—Ç–æ–Ω—ã 2024 –†–æ—Å—Å–∏—è",
            "AI –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏—è –°–ü–±",
            "Data Science –∫–æ–Ω—Ñ–µ—Ä–µ–Ω—Ü–∏—è –°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥",
            "–≤–µ–±-—Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞ –º–∏—Ç–∞–ø",
            "DevOps –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏—è"
        ]
        
        all_web_events = []
        
        for query in search_queries:
            try:
                events = await self.web_searcher.search_real_events(query, max_events=3)
                all_web_events.extend(events)
                await asyncio.sleep(1)  # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –≤–µ–±-–ø–æ–∏—Å–∫–∞ '{query}': {e}")
                continue
        
        return all_web_events
    
    async def _search_with_llm(self):
        """–ò—â–µ—Ç –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏—è —á–µ—Ä–µ–∑ LLM"""
        try:
            print("üß† –ó–∞–ø—É—Å–∫–∞–µ–º LLM-–ø–æ–∏—Å–∫ –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏–π...")
            
            # –ü–æ–∏—Å–∫ –ø–æ –ø–æ–ø—É–ª—è—Ä–Ω—ã–º —Ç–µ–º–∞–º
            popular_themes = [
                ['AI', '–∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç', '–º–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ'],
                ['Data Science', '–∞–Ω–∞–ª–∏—Ç–∏–∫–∞ –¥–∞–Ω–Ω—ã—Ö'],
                ['–≤–µ–±-—Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞', 'frontend', 'backend'],
                ['–º–æ–±–∏–ª—å–Ω–∞—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞', 'iOS', 'Android'],
                ['–∫–∏–±–µ—Ä–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å', '–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å'],
                ['–æ–±–ª–∞—á–Ω—ã–µ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏', 'DevOps'],
                ['–±–ª–æ–∫—á–µ–π–Ω', '–∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç—ã'],
                ['–≥–µ–π–º–¥–µ–≤', '—Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞ –∏–≥—Ä']
            ]
            
            all_llm_events = []
            
            for themes in popular_themes:
                try:
                    events = await self.search_manager.enhanced_search(
                        'themes', 
                        themes, 
                        max_results=8
                    )
                    all_llm_events.extend(events)
                    print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(events)} –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏–π –ø–æ —Ç–µ–º–∞–º: {', '.join(themes)}")
                    await asyncio.sleep(2)  # –ó–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
                except Exception as e:
                    print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –ø–æ —Ç–µ–º–∞–º {themes}: {e}")
                    continue
            
            # –ü–æ–∏—Å–∫ –±–ª–∏–∂–∞–π—à–∏—Ö –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏–π
            try:
                upcoming_events = await self.search_manager.enhanced_search(
                    'upcoming',
                    30,  # –±–ª–∏–∂–∞–π—à–∏–µ 30 –¥–Ω–µ–π
                    max_results=10
                )
                all_llm_events.extend(upcoming_events)
                print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(upcoming_events)} –±–ª–∏–∂–∞–π—à–∏—Ö –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏–π")
            except Exception as e:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –±–ª–∏–∂–∞–π—à–∏—Ö –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏–π: {e}")
            
            return self._remove_duplicates(all_llm_events)
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ LLM-–ø–æ–∏—Å–∫–∞: {e}")
            return []
    
    def _parse_additional_sources(self):
        """
        –ü–∞—Ä—Å–∏–Ω–≥ —Å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö —Ä–µ–∞–ª—å–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
        """
        additional_events = []
        
        # –ü–∞—Ä—Å–∏–Ω–≥ —Å —Å–∞–π—Ç–∞ –ò–¢–ú–û
        try:
            itmo_events = self._parse_itmo_website()
            if itmo_events and isinstance(itmo_events, list):
                additional_events.extend(itmo_events)
                print(f"‚úÖ –°–ø–∞—Ä—Å–µ–Ω–æ {len(itmo_events)} –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏–π —Å –ò–¢–ú–û")
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –ò–¢–ú–û: {e}")
        
        # –ü–∞—Ä—Å–∏–Ω–≥ —Å TimePad (–ø—Ä–∏–º–µ—Ä)
        try:
            timepad_events = self._parse_timepad_example()
            if timepad_events and isinstance(timepad_events, list):
                additional_events.extend(timepad_events)
                print(f"‚úÖ –°–ø–∞—Ä—Å–µ–Ω–æ {len(timepad_events)} –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏–π —Å TimePad")
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ TimePad: {e}")
        
        return additional_events
    
    def _parse_itmo_website(self):
        """
        –ü—Ä–∏–º–µ—Ä –ø–∞—Ä—Å–∏–Ω–≥–∞ —Å —Å–∞–π—Ç–∞ –ò–¢–ú–û
        –í —Ä–µ–∞–ª—å–Ω–æ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ –∑–¥–µ—Å—å –±—É–¥–µ—Ç –ø–æ–ª–Ω–æ—Ü–µ–Ω–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥
        """
        # –ó–∞–≥–ª—É—à–∫–∞ –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏
        return [
            {
                "title": "–î–µ–Ω—å –æ—Ç–∫—Ä—ã—Ç—ã—Ö –¥–≤–µ—Ä–µ–π –º–∞–≥–∏—Å—Ç—Ä–∞—Ç—É—Ä—ã –ò–¢–ú–û",
                "date": "2025-04-10",
                "location": "–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥, –£–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç –ò–¢–ú–û",
                "audience": 200,
                "type": "–æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–æ–µ –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏–µ",
                "themes": ["–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ", "–º–∞–≥–∏—Å—Ç—Ä–∞—Ç—É—Ä–∞", "IT"],
                "speakers": ["–ü—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª–∏ –ò–¢–ú–û", "–°—Ç—É–¥–µ–Ω—Ç—ã"],
                "description": "–î–µ–Ω—å –æ—Ç–∫—Ä—ã—Ç—ã—Ö –¥–≤–µ—Ä–µ–π –º–∞–≥–∏—Å—Ç–µ—Ä—Å–∫–∏—Ö –ø—Ä–æ–≥—Ä–∞–º–º –£–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç–∞ –ò–¢–ú–û",
                "registration_info": "–†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –Ω–∞ —Å–∞–π—Ç–µ itmo.ru",
                "source": "itmo_parsed",
                "url": "https://itmo.ru"
            }
        ]
    
    def _parse_timepad_example(self):
        """
        –ü—Ä–∏–º–µ—Ä –ø–∞—Ä—Å–∏–Ω–≥–∞ —Å TimePad
        """
        return [
            {
                "title": "Data Science Hackathon",
                "date": "2025-05-20",
                "location": "–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥, –û—Ñ–∏—Å –Ø–Ω–¥–µ–∫—Å",
                "audience": 120,
                "type": "—Ö–∞–∫–∞—Ç–æ–Ω",
                "themes": ["Data Science", "ML", "–∞–Ω–∞–ª–∏—Ç–∏–∫–∞"],
                "speakers": ["–≠–∫—Å–ø–µ—Ä—Ç—ã Data Science"],
                "description": "–•–∞–∫–∞—Ç–æ–Ω –ø–æ Data Science —Å —Ä–µ–∞–ª—å–Ω—ã–º–∏ –∫–µ–π—Å–∞–º–∏",
                "registration_info": "–†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –Ω–∞ TimePad",
                "source": "timepad_parsed",
                "url": "https://timepad.ru"
            }
        ]
    
    def _remove_duplicates(self, events):
        """–£–¥–∞–ª—è–µ—Ç –¥—É–±–ª–∏–∫–∞—Ç—ã –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏–π"""
        if not events or not isinstance(events, list):
            return []
            
        seen_titles = set()
        unique_events = []
        
        for event in events:
            if isinstance(event, dict) and 'title' in event:
                title = event['title'].lower().strip()
                if title not in seen_titles:
                    seen_titles.add(title)
                    unique_events.append(event)
        
        return unique_events
    
    def save_events(self, events):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏—è –≤ JSON —Ñ–∞–π–ª"""
        try:
            # –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ events - —ç—Ç–æ —Å–ø–∏—Å–æ–∫
            if not isinstance(events, list):
                events = []
                
            # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–∞-–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
            events_data = {
                "metadata": {
                    "last_updated": datetime.now().isoformat(),
                    "total_events": len(events),
                    "sources_used": ["web_search", "llm_search", "sample_database", "itmo", "timepad"]
                },
                "events": events
            }
            
            # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É data –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç
            os.makedirs(os.path.dirname(config.EVENTS_DB), exist_ok=True)
            
            with open(config.EVENTS_DB, 'w', encoding='utf-8') as f:
                json.dump(events_data, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏–π: {e}")
    
    def load_events(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏—è –∏–∑ JSON —Ñ–∞–π–ª–∞"""
        try:
            if not os.path.exists(config.EVENTS_DB):
                return []
                
            with open(config.EVENTS_DB, 'r', encoding='utf-8') as f:
                data = json.load(f)
                # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å–æ–±—ã—Ç–∏—è –∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
                if isinstance(data, dict) and 'events' in data:
                    return data.get('events', [])
                elif isinstance(data, list):
                    return data
                else:
                    return []
        except FileNotFoundError:
            return []
        except json.JSONDecodeError:
            return []
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏–π: {e}")
            return []
    
    def get_events_statistics(self):
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏—è–º"""
        events = self.load_events()
        
        if not events:
            return {"total": 0}
        
        stats = {
            "total": len(events),
            "by_type": {},
            "by_month": {},
            "by_source": {}
        }
        
        for event in events:
            if not isinstance(event, dict):
                continue
                
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ç–∏–ø–∞–º
            event_type = event.get('type', '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')
            stats["by_type"][event_type] = stats["by_type"].get(event_type, 0) + 1
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –º–µ—Å—è—Ü–∞–º
            try:
                date_str = event.get('date', '')
                if date_str:
                    month = datetime.strptime(date_str, '%Y-%m-%d').strftime('%Y-%m')
                    stats["by_month"][month] = stats["by_month"].get(month, 0) + 1
            except:
                pass
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º
            source = event.get('source', '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')
            stats["by_source"][source] = stats["by_source"].get(source, 0) + 1
        
        return stats
    
    async def close(self):
        """–ó–∞–∫—Ä—ã–≤–∞–µ—Ç –≤–µ–±-—Å–µ—Å—Å–∏—é"""
        await self.web_searcher.close()